{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\"\n",
    "import shfl\n",
    "import torch\n",
    "import copy\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "import cv2\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "from shfl.private import UnprotectedAccess\n",
    "from CIT.model import CITModel\n",
    "from utils import get_federated_data_csv, get_data_csv\n",
    "from ClassifierModel import ClassifierModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"data_path\":\"../data/COVIDGR1.0-Segmentadas\", \n",
    "        \"csv_path\": \"../partitions/partition1.csv\",\n",
    "        \"output_path\": \"../weights\",\n",
    "        \"input_path\": \"\",\n",
    "        \"model_name\":\"transferlearning.model\", \n",
    "        \"label_bin\": \"lb.pickle\", \n",
    "        \"batch_size\": 8,\n",
    "        \"federated_rounds\": 1,\n",
    "        \"epochs_per_FL_round\": 100,\n",
    "        \"num_nodes\": 3,\n",
    "        \"size_averaging\": 1,\n",
    "        \"random_rotation\": 0,\n",
    "        \"random_shift\": 0, \n",
    "        \"random_zoom\": 0,\n",
    "        \"horizontal_flip\": False,        \n",
    "        \"finetune\": True,\n",
    "        \"train_network\": True}\n",
    "\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cit_builder():    \n",
    "    return CITModel(['N', 'P'], classifier_name = \"resnet18\", lambda_values = [0.1], folds = 1, batch_size=args[\"batch_size\"], epochs=args[\"epochs_per_FL_round\"], device='cpu')\n",
    "def classifier_builder(G_dict, dict_labels):\n",
    "    return ClassifierModel(G_dict, dict_labels, batch_size=args[\"batch_size\"], epochs=args[\"epochs_per_FL_round\"], finetune = args[\"finetune\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['N', 'P']\n",
    "b = ['NTN', 'NTP', 'PTP', 'PTN']\n",
    "lb1 = LabelBinarizer()\n",
    "lb2 = LabelBinarizer()\n",
    "lb1.fit(a)\n",
    "lb2.fit(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "NTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTP\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "PTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n",
      "NTN\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/COVIDGR1.0-TransformadasSplit\"\n",
    "train_path = os.path.join(path, \"train\")\n",
    "test_path = os.path.join(path, \"test\")\n",
    "height = width = 224\n",
    "\n",
    "\n",
    "t_train_data = []\n",
    "t_train_labels = []\n",
    "t_test_data = []\n",
    "t_test_labels = []\n",
    "        \n",
    "train_files = list(paths.list_images(train_path))\n",
    "        \n",
    "for image_path in train_files:\n",
    "    label = image_path.split(os.path.sep)[-2]\n",
    "    print(label)\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    if height != None and width != None:\n",
    "        image = cv2.resize(image, (height, width))\n",
    "            \n",
    "    t_train_data.append(image)\n",
    "    t_train_labels.append(label)\n",
    "            \n",
    "test_files = list(paths.list_images(test_path))\n",
    "        \n",
    "for image_path in test_files:\n",
    "    label = image_path.split(os.path.sep)[-2]\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    if height != None and width != None:\n",
    "        image = cv2.resize(image, (height, width))\n",
    "            \n",
    "    t_test_data.append(image)\n",
    "    t_test_labels.append(label)\n",
    "    \n",
    "    \n",
    "t_train_data = np.array(t_train_data)\n",
    "t_train_labels = np.array(t_train_labels)\n",
    "t_test_data = np.array(t_test_data)\n",
    "t_test_labels = np.array(t_test_labels)\n",
    "        \n",
    "t_train_labels = lb2.transform(t_train_labels)\n",
    "t_test_labels = lb2.transform(t_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(t_train_labels[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 27s 177ms/step - loss: 0.7089 - categorical_accuracy: 0.6664 - val_loss: 0.7602 - val_categorical_accuracy: 0.6397\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 11s 73ms/step - loss: 0.4038 - categorical_accuracy: 0.8189 - val_loss: 0.2053 - val_categorical_accuracy: 0.9265\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 11s 71ms/step - loss: 0.2290 - categorical_accuracy: 0.9164 - val_loss: 0.0337 - val_categorical_accuracy: 0.9926\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 11s 70ms/step - loss: 0.1679 - categorical_accuracy: 0.9377 - val_loss: 0.1408 - val_categorical_accuracy: 0.9412\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 11s 73ms/step - loss: 0.1218 - categorical_accuracy: 0.9467 - val_loss: 0.1324 - val_categorical_accuracy: 0.9559\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 11s 73ms/step - loss: 0.1314 - categorical_accuracy: 0.9607 - val_loss: 0.9704 - val_categorical_accuracy: 0.6544\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 11s 75ms/step - loss: 0.0765 - categorical_accuracy: 0.9762 - val_loss: 0.0879 - val_categorical_accuracy: 0.9779\n",
      "Epoch 8/100\n",
      "153/153 [==============================] - 11s 72ms/step - loss: 0.0692 - categorical_accuracy: 0.9705 - val_loss: 0.7476 - val_categorical_accuracy: 0.7059\n",
      "Epoch 9/100\n",
      "153/153 [==============================] - 11s 73ms/step - loss: 0.0943 - categorical_accuracy: 0.9738 - val_loss: 0.3990 - val_categorical_accuracy: 0.8824\n",
      "Epoch 10/100\n",
      "153/153 [==============================] - 11s 72ms/step - loss: 0.0743 - categorical_accuracy: 0.9730 - val_loss: 0.4430 - val_categorical_accuracy: 0.8750\n",
      "Epoch 11/100\n",
      "153/153 [==============================] - 11s 72ms/step - loss: 0.0398 - categorical_accuracy: 0.9852 - val_loss: 0.0424 - val_categorical_accuracy: 0.9926\n",
      "Epoch 12/100\n",
      "153/153 [==============================] - 11s 72ms/step - loss: 0.0301 - categorical_accuracy: 0.9918 - val_loss: 0.8193 - val_categorical_accuracy: 0.6985\n",
      "Epoch 13/100\n",
      "152/153 [============================>.] - ETA: 0s - loss: 0.0242 - categorical_accuracy: 0.9926Restoring model weights from the end of the best epoch.\n",
      "153/153 [==============================] - 12s 78ms/step - loss: 0.0241 - categorical_accuracy: 0.9926 - val_loss: 0.5905 - val_categorical_accuracy: 0.8382\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "from ClassifierModel import ClassifierModel\n",
    "\n",
    "dict_labels = { 'PTP' : np.argmax(lb2.transform(['PTP'])[0]) , 'PTN' : np.argmax(lb2.transform(['PTN'])[0]) , \n",
    "                'NTP' : np.argmax(lb2.transform(['NTP'])[0]) , 'NTN' : np.argmax(lb2.transform(['NTN'])[0]), \n",
    "                'P' : lb1.transform(['P'])[0][0], 'N' : lb1.transform(['N'])[0][0]\n",
    "              } \n",
    "\n",
    "classifier_model = classifier_builder(cit_builder()._G_dict, dict_labels)\n",
    "classifier_model.train(t_train_data, t_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340\n",
      "Accuracy 4 clases: 0.6441176470588236\n",
      "Numero de veces no concuerda: 17\n",
      "[['0638920510-120520' 'N' 'N']\n",
      " ['0787337378-030420' 'N' 'N']\n",
      " ['0708178611-250420' 'N' 'N']\n",
      " ['0696851031-200420' 'N' 'N']\n",
      " ['1705154118-130420' 'N' 'N']\n",
      " ['0818483876-230420' 'N' 'N']\n",
      " ['0806768094-240420' 'N' 'N']\n",
      " ['0720838525-130420' 'N' 'N']\n",
      " ['0761057351-200420' 'N' 'N']\n",
      " ['0915828834-010419' 'N' 'N']\n",
      " ['0725232423-170417' 'N' 'N']\n",
      " ['0700474989-100420' 'N' 'P']\n",
      " ['0692270813-310320' 'N' 'N']\n",
      " ['0816904392-231019' 'N' 'N']\n",
      " ['0697685029-030420' 'N' 'P']\n",
      " ['0736465730-260320' 'N' 'N']\n",
      " ['0702106108-240320' 'N' 'N']\n",
      " ['0597018126-150218' 'N' 'N']\n",
      " ['0694973776-040420' 'N' 'N']\n",
      " ['0384486981-110420' 'N' 'N']\n",
      " ['1553588887-290420' 'N' 'N']\n",
      " ['0943193342-220220' 'N' 'N']\n",
      " ['0690934031-140420' 'N' 'N']\n",
      " ['0818292304-140420' 'N' 'N']\n",
      " ['0930410964-130420' 'N' 'N']\n",
      " ['0730235906-280420' 'N' 'N']\n",
      " ['0714822000-280320' 'N' 'N']\n",
      " ['0711477823-220420' 'N' 'N']\n",
      " ['0380844734-100420' 'N' 'N']\n",
      " ['1530852895-260420' 'N' 'N']\n",
      " ['0706436348-070520' 'N' 'N']\n",
      " ['0820391645-230420' 'N' 'N']\n",
      " ['0712491673-150420' 'N' 'N']\n",
      " ['1275873241-180320' 'N' 'N']\n",
      " ['0268438104-070520' 'N' 'N']\n",
      " ['1022484686-200420' 'N' 'N']\n",
      " ['0712835015-230420' 'N' 'N']\n",
      " ['0823551623-030520' 'N' 'N']\n",
      " ['0730239542-250320' 'N' 'N']\n",
      " ['0696800511-180119' 'N' 'N']\n",
      " ['1389821161-120520' 'N' 'N']\n",
      " ['0693376613-290420' 'N' 'N']\n",
      " ['0720144973-130420' 'N' 'N']\n",
      " ['0805609047-070520' 'N' 'N']\n",
      " ['0727230320-060520' 'N' 'N']\n",
      " ['0693526860-090320' 'N' 'N']\n",
      " ['0817902583-210420' 'N' 'N']\n",
      " ['0817293305-260420' 'N' 'N']\n",
      " ['0637784701-220420' 'N' 'N']\n",
      " ['1536569532-190420' 'N' 'N']\n",
      " ['0737426535-130520' 'N' 'N']\n",
      " ['0814693907-070520' 'N' 'N']\n",
      " ['0698782947-050520' 'N' 'N']\n",
      " ['0693184633-010420' 'N' 'N']\n",
      " ['0723357390-240320' 'N' 'N']\n",
      " ['0952558993-010219' 'N' 'N']\n",
      " ['1234902158-170620' 'N' 'N']\n",
      " ['0704955480-010420' 'N' 'N']\n",
      " ['0809834813-130420' 'N' 'N']\n",
      " ['1050553052-170619' 'N' 'N']\n",
      " ['0706615190-260420' 'N' 'N']\n",
      " ['1228631514-200420' 'N' 'N']\n",
      " ['0697277023-300420' 'N' 'N']\n",
      " ['1320947828-140520' 'N' 'P']\n",
      " ['0707678857-010219' 'N' 'N']\n",
      " ['1280818120-260418' 'N' 'N']\n",
      " ['0693896975-060520' 'N' 'N']\n",
      " ['0693554849-270320' 'N' 'N']\n",
      " ['0697122732-220420' 'N' 'N']\n",
      " ['0015305688-170518' 'N' 'N']\n",
      " ['0901576706-181119' 'N' 'N']\n",
      " ['0690082956-300420' 'N' 'N']\n",
      " ['0686154557-070520' 'N' 'N']\n",
      " ['1616818137-190320' 'N' 'N']\n",
      " ['0727979846-290518' 'N' 'N']\n",
      " ['1659510968-270320' 'N' 'N']\n",
      " ['0689457914-250320' 'N' 'N']\n",
      " ['0696259331-120520' 'N' 'N']\n",
      " ['0737733396-250320' 'N' 'N']\n",
      " ['0703343765-170420' 'N' 'N']\n",
      " ['0713848057-280420' 'N' 'N']\n",
      " ['0946592079-020419' 'N' 'N']\n",
      " ['1202374927-191119' 'N' 'N']\n",
      " ['0735812291-300420' 'N' 'N']\n",
      " ['0804582059-280420' 'N' 'N']\n",
      " ['1184834596-250320' 'P' 'N']\n",
      " ['0640261130-280320' 'P' 'N']\n",
      " ['0702118535-250320' 'P' 'N']\n",
      " ['0815745951-210320' 'P' 'N']\n",
      " ['0699603811-240320' 'P' 'P']\n",
      " ['0814512536-220320' 'P' 'N']\n",
      " ['0811853625-230320' 'P' 'P']\n",
      " ['0696245183-120320' 'P' 'N']\n",
      " ['0706795753-300320' 'P' 'P']\n",
      " ['0723641421-260320' 'P' 'N']\n",
      " ['0720504075-130520' 'P' 'N']\n",
      " ['1092863139-060420' 'P' 'N']\n",
      " ['0789541706-050420' 'P' 'N']\n",
      " ['1704688720-080420' 'P' 'N']\n",
      " ['0901551848-230320' 'P' 'N']\n",
      " ['0789992956-310320' 'P' 'N']\n",
      " ['0684214355-230420' 'P' 'N']\n",
      " ['0707929946-180420' 'P' 'N']\n",
      " ['0707274285-260320' 'P' 'P']\n",
      " ['0688444363-130420' 'P' 'N']\n",
      " ['0794301271-020420' 'P' 'N']\n",
      " ['0725427635-010420' 'P' 'N']\n",
      " ['0732877639-250320' 'P' 'P']\n",
      " ['0727343080-190320' 'P' 'N']\n",
      " ['0788229273-200320' 'P' 'P']\n",
      " ['0736515543-010420' 'P' 'N']\n",
      " ['0284464221-260320' 'P' 'N']\n",
      " ['0719272579-300320' 'P' 'P']\n",
      " ['0734745392-050520' 'P' 'N']\n",
      " ['0699984535-310320' 'P' 'N']\n",
      " ['0687755461-280320' 'P' 'P']\n",
      " ['0683002057-010420' 'P' 'P']\n",
      " ['0811138552-280420' 'P' 'P']\n",
      " ['0795165884-010420' 'P' 'N']\n",
      " ['1051052907-310320' 'P' 'N']\n",
      " ['0732640795-200420' 'P' 'N']\n",
      " ['0698175079-200320' 'P' 'N']\n",
      " ['0690849054-250320' 'P' 'N']\n",
      " ['0692720750-190320' 'P' 'P']\n",
      " ['0708427676-270420' 'P' 'N']\n",
      " ['1251194421-300320' 'P' 'N']\n",
      " ['0820261101-060420' 'P' 'P']\n",
      " ['0706712695-270320' 'P' 'N']\n",
      " ['0712690626-160420' 'P' 'N']\n",
      " ['0788046791-080520' 'P' 'N']\n",
      " ['0735342045-240320' 'P' 'P']\n",
      " ['0683491404-210320' 'P' 'P']\n",
      " ['0737301041-130420' 'P' 'N']\n",
      " ['0675989563-300320' 'P' 'P']\n",
      " ['0950028610-190320' 'P' 'N']\n",
      " ['0704785631-200320' 'P' 'P']\n",
      " ['0758894655-230320' 'P' 'P']\n",
      " ['0696267213-190320' 'P' 'P']\n",
      " ['0686599646-230320' 'P' 'N']\n",
      " ['0696985215-160420' 'P' 'N']\n",
      " ['0711188641-220320' 'P' 'N']\n",
      " ['1489514529-020420' 'P' 'N']\n",
      " ['1142339304-240320' 'P' 'N']\n",
      " ['0635360610-290320' 'P' 'N']\n",
      " ['0805983206-270320' 'P' 'P']\n",
      " ['0683682471-180320' 'P' 'P']\n",
      " ['0733198850-250320' 'P' 'N']\n",
      " ['0346676179-060420' 'P' 'N']\n",
      " ['0708212256-220320' 'P' 'N']\n",
      " ['0738060065-260320' 'P' 'P']\n",
      " ['0721775280-300320' 'P' 'N']\n",
      " ['0816187202-290320' 'P' 'N']\n",
      " ['0397375756-270320' 'P' 'P']\n",
      " ['0734898673-180420' 'P' 'N']\n",
      " ['0703985682-010420' 'P' 'N']\n",
      " ['0956939151-280320' 'P' 'N']\n",
      " ['0686819110-280320' 'P' 'N']\n",
      " ['0681303244-230320' 'P' 'P']\n",
      " ['1143733373-040420' 'P' 'P']\n",
      " ['0704323667-130420' 'P' 'P']\n",
      " ['0708407266-240420' 'P' 'N']\n",
      " ['1129490137-220320' 'P' 'P']\n",
      " ['0735509571-250320' 'P' 'P']\n",
      " ['0797052031-240320' 'P' 'N']\n",
      " ['0727218903-170420' 'P' 'N']\n",
      " ['0736070757-190320' 'P' 'N']\n",
      " ['0930487049-270320' 'P' 'N']\n",
      " ['0687841650-210320' 'P' 'P']\n",
      " ['1042956841-270320' 'P' 'P']\n",
      " ['0699134773-210320' 'P' 'N']]\n",
      "{'N': {'precision': 0.5942028985507246, 'recall': 0.9647058823529412, 'f1-score': 0.7354260089686098, 'support': 85}, 'P': {'precision': 0.90625, 'recall': 0.3411764705882353, 'f1-score': 0.4957264957264957, 'support': 85}, 'accuracy': 0.6529411764705882, 'macro avg': {'precision': 0.7502264492753623, 'recall': 0.6529411764705882, 'f1-score': 0.6155762523475528, 'support': 170}, 'weighted avg': {'precision': 0.7502264492753623, 'recall': 0.6529411764705882, 'f1-score': 0.6155762523475528, 'support': 170}}\n",
      "0.6529411764705882\n"
     ]
    }
   ],
   "source": [
    "dict_labels = { 'PTP' : np.argmax(lb2.transform(['PTP'])[0]) , 'PTN' : np.argmax(lb2.transform(['PTN'])[0]) , \n",
    "                'NTP' : np.argmax(lb2.transform(['NTP'])[0]) , 'NTN' : np.argmax(lb2.transform(['NTN'])[0])\n",
    "              } \n",
    "\n",
    "print(len(test_files))\n",
    "\n",
    "new_test_files = copy.deepcopy(test_files)\n",
    "\n",
    "get_classification_report(new_test_files, dict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
