{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import subprocess\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import shfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"data_path\":\"../data/generated/COVIDGR1.0reducido/transformed\", \n",
    "        \"output_path\": \"../weights\",\n",
    "        \"input_path\": \"\",\n",
    "        \"model_name\":\"transferlearning.model\", \n",
    "        \"label_bin\": \"lb.pickle\", \n",
    "        \"batch_size\": 8,\n",
    "        \"federated_rounds\": 1,\n",
    "        \"epochs_per_FL_round\": 1,\n",
    "        \"num_nodes\": 2,\n",
    "        \"size_averaging\": 1,\n",
    "        \"random_rotation\": 0,\n",
    "        \"random_shift\": 0, \n",
    "        \"random_zoom\": 0,\n",
    "        \"horizontal_flip\": False,        \n",
    "        \"finetune\": True,\n",
    "        \"train_network\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training for labels: {'PTN', 'PTP', 'NTP', 'NTN'}\n",
      "[INFO] loading images...\n",
      "[INFO] done\n"
     ]
    }
   ],
   "source": [
    "LABELS = set([\"NTN\", \"NTP\", \"PTN\", \"PTP\"])\n",
    "print(\"[INFO] training for labels: \" + str(LABELS))\n",
    "\n",
    "imagePaths = list(paths.list_images(os.path.join(args[\"data_path\"])))\n",
    "data = []\n",
    "labels = []\n",
    "#print(imagePaths)\n",
    "print(\"[INFO] loading images...\")\n",
    "for imagePath in imagePaths:\n",
    "    # extract the class label from the filename\n",
    "    imgname = imagePath.split(os.path.sep)[-1]\n",
    "    \n",
    "    name, class_transf_ext = imgname.split('_')\n",
    "    class_transf = class_transf_ext.split('.')[0]\n",
    "    class_label, transf = class_transf.split('T18')\n",
    "    label = class_label+\"T\"+transf\n",
    "\n",
    "    # load the image, convert it to RGB channel ordering, and resize\n",
    "    # it to be a fixed 224x224 pixels, ignoring aspect ratio\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "\n",
    "    # update the data and labels lists, respectively\n",
    "    data.append(image)\n",
    "    labels.append(label)\n",
    "\n",
    "# convert the data and labels to NumPy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# perform one-hot encoding on the labels\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "print(\"[INFO] done\")\n",
    "#print(len(LABELS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Number of train images: 28\n",
      "[INFO] Number of test images: 8\n",
      "[[0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]]\n",
      "[INFO] Distributing the train set across the nodes...\n",
      "[INFO] done\n"
     ]
    }
   ],
   "source": [
    "#database = shfl.data_base.LabeledDatabase(data, labels)\n",
    "database = shfl.data_base.DatabaseFromDirectory(\"../data/generated/COVIDGR1.0reducido/transformed-split\", height = 224, width = 224)\n",
    "train_data, train_labels, test_data, test_labels = database.load_data()\n",
    "\n",
    "print(\"[INFO] Number of train images: \" + str(len(train_data)))\n",
    "print(\"[INFO] Number of test images: \" + str(len(test_data)))\n",
    "\n",
    "print(\"[INFO] Distributing the train set across the nodes...\")\n",
    "iid_distribution = shfl.data_distribution.IidDataDistribution(database)\n",
    "federated_data, test_data, test_label = iid_distribution.get_federated_data(num_nodes=args[\"num_nodes\"])\n",
    "print(\"[INFO] done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "\"\"\"\n",
    "datagen_train = ImageDataGenerator(\n",
    "    preprocessing_function = preprocess_input,\n",
    "    rotation_range = args[\"random_rotation\"],\n",
    "    width_shift_range = args[\"random_shift\"],\n",
    "    height_shift_range = args[\"random_shift\"],\n",
    "    zoom_range = args[\"random_zoom\"],\n",
    "    horizontal_flip = args[\"horizontal_flip\"]\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "datagen_train = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "datagen_val = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "class TransferLearningModel(shfl.model.DeepLearningModel):    \n",
    "    \n",
    "    def train(self, data, labels):\n",
    "        #self._check_data(data)\n",
    "        #self._check_labels(labels)\n",
    "\n",
    "        #early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
    "        self._model.fit(\n",
    "            x=datagen_train.flow(data, labels, batch_size=args[\"batch_size\"]),\n",
    "            steps_per_epoch=len(data) // args[\"batch_size\"],\n",
    "            validation_data=datagen_val.flow(test_data, test_labels),\n",
    "            validation_steps=len(test_data) // args[\"batch_size\"],\n",
    "            epochs=self._epochs\n",
    "        )\n",
    "\n",
    "def model_builder():\n",
    "    \n",
    "    resnet50 = tf.keras.applications.ResNet50(include_top = False, weights = 'imagenet', pooling = 'avg', input_tensor=Input(shape=(224, 224, 3)))\n",
    "    \n",
    "    if (args[\"finetune\"]):\n",
    "        resnet50.trainable = False\n",
    "    else: \n",
    "        resnet50.trainable = True\n",
    "    \n",
    "    # Add last layers\n",
    "    x = resnet50.output\n",
    "    # x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "    # x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    predictions = tf.keras.layers.Dense(len(LABELS), activation = 'softmax')(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs = resnet50.input, outputs = predictions)\n",
    "    \n",
    "    criterion = tf.keras.losses.CategoricalCrossentropy()\n",
    "    optimizer = tf.keras.optimizers.SGD(lr = 1e-3, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "    metrics = [tf.keras.metrics.categorical_accuracy]\n",
    "    \n",
    "    return TransferLearningModel(model=model, criterion=criterion, optimizer=optimizer, metrics=metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Accuracy round 0\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.6243 - categorical_accuracy: 0.3750 - val_loss: 2.2873 - val_categorical_accuracy: 0.2500\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1.5286 - categorical_accuracy: 0.2500 - val_loss: 2.3227 - val_categorical_accuracy: 0.2500\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x7fbe76a3fc88>: [2.5782532691955566, 0.25]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x7fbe76a3f4e0>: [2.6029462814331055, 0.25]\n",
      "Global model test performance : [2.59030818939209, 0.25]\n",
      "\n",
      "\n",
      "\n",
      "[INFO] saving model ...\n",
      "[INFO] done\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Train the network:\n",
    "epochs_per_FL_round=args[\"epochs_per_FL_round\"]\n",
    "aggregator = shfl.federated_aggregator.FedAvgAggregator()\n",
    "federated_government = shfl.federated_government.FederatedGovernment(model_builder, federated_data, aggregator)\n",
    "if args[\"train_network\"]:\n",
    "    federated_government.run_rounds(args[\"federated_rounds\"], test_data, test_label)\n",
    "    print(\"[INFO] saving model ...\")\n",
    "    federated_government.global_model._model.save( os.path.join(args[\"output_path\"], args[\"model_name\"]) )\n",
    "    print(\"[INFO] done\")\n",
    "else:\n",
    "    print(\"[INFO] loading pre-computed model ...\")\n",
    "    model_path = os.path.join(args[\"output_path\"], args[\"model_name\"])\n",
    "    federated_government.global_model._model = load_model(model_path)\n",
    "    #lb = pickle.loads(open(os.path.join(args[\"output_path\"], args[\"label_bin\"]), \"rb\").read())\n",
    "    print(\"[INFO] done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating federated network...\n",
      "[1 1 1 1 1 1 1 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NTN       0.00      0.00      0.00         2\n",
      "         NTP       0.25      1.00      0.40         2\n",
      "         PTN       0.00      0.00      0.00         2\n",
      "         PTP       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.25         8\n",
      "   macro avg       0.06      0.25      0.10         8\n",
      "weighted avg       0.06      0.25      0.10         8\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# evaluate the federated network\n",
    "print(\"[INFO] evaluating federated network...\")\n",
    "predictions = federated_government.global_model.predict(data=test_data.astype(\"float32\"))\n",
    "\n",
    "print(classification_report(test_labels.argmax(axis=1), predictions, target_names=lb.classes_) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 26 193 187]\n",
      "   [ 75  67 206]\n",
      "   [ 69 232 194]\n",
      "   ...\n",
      "   [ 47 221 192]\n",
      "   [124  86 212]\n",
      "   [124  69 242]]\n",
      "\n",
      "  [[ 62 230  79]\n",
      "   [234  87  39]\n",
      "   [217 218  40]\n",
      "   ...\n",
      "   [120 233  35]\n",
      "   [142  65  62]\n",
      "   [226 235 188]]\n",
      "\n",
      "  [[228 153 212]\n",
      "   [199  68 112]\n",
      "   [160 204 158]\n",
      "   ...\n",
      "   [ 76 158  82]\n",
      "   [ 90 112  83]\n",
      "   [184 228  37]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 63  63 210]\n",
      "   [ 97  92  60]\n",
      "   [105  74  60]\n",
      "   ...\n",
      "   [158  66  55]\n",
      "   [166 119  83]\n",
      "   [147  73 131]]\n",
      "\n",
      "  [[ 53 179 231]\n",
      "   [ 45 194 129]\n",
      "   [ 66 146  21]\n",
      "   ...\n",
      "   [190  98 155]\n",
      "   [193 159  51]\n",
      "   [190 209 146]]\n",
      "\n",
      "  [[ 29  23  63]\n",
      "   [217  36  48]\n",
      "   [226  34  41]\n",
      "   ...\n",
      "   [197 106 176]\n",
      "   [208 152 196]\n",
      "   [188  86 182]]]\n",
      "\n",
      "\n",
      " [[[ 41 186 166]\n",
      "   [ 66 225 188]\n",
      "   [ 61 214 172]\n",
      "   ...\n",
      "   [ 59 198 190]\n",
      "   [123  85 196]\n",
      "   [ 96  64 249]]\n",
      "\n",
      "  [[226  52  37]\n",
      "   [205  71  31]\n",
      "   [190 207  37]\n",
      "   ...\n",
      "   [201 177  84]\n",
      "   [196 230  37]\n",
      "   [220 221 195]]\n",
      "\n",
      "  [[220 155  78]\n",
      "   [197  59 103]\n",
      "   [176 182 150]\n",
      "   ...\n",
      "   [210 174 136]\n",
      "   [226 217  73]\n",
      "   [211 206  49]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 46  60 200]\n",
      "   [ 29 103 184]\n",
      "   [ 59  77 134]\n",
      "   ...\n",
      "   [165  36  32]\n",
      "   [176  54 197]\n",
      "   [155  29 182]]\n",
      "\n",
      "  [[ 29 181 219]\n",
      "   [ 31 190 220]\n",
      "   [ 34 185 165]\n",
      "   ...\n",
      "   [209  59 119]\n",
      "   [201  78 231]\n",
      "   [206 162 172]]\n",
      "\n",
      "  [[230  32  57]\n",
      "   [211  62  53]\n",
      "   [179  53  59]\n",
      "   ...\n",
      "   [210  76 163]\n",
      "   [204 100 214]\n",
      "   [195  42 204]]]\n",
      "\n",
      "\n",
      " [[[ 39 187 183]\n",
      "   [ 62  58 195]\n",
      "   [ 63 222 178]\n",
      "   ...\n",
      "   [ 42 223 187]\n",
      "   [126  92 210]\n",
      "   [125  63 240]]\n",
      "\n",
      "  [[245 230  86]\n",
      "   [225  79  37]\n",
      "   [212 214  38]\n",
      "   ...\n",
      "   [115 239  31]\n",
      "   [144  77  62]\n",
      "   [226 231 190]]\n",
      "\n",
      "  [[229 148 228]\n",
      "   [195  65 108]\n",
      "   [156 191 159]\n",
      "   ...\n",
      "   [ 82 166  85]\n",
      "   [ 30  51  85]\n",
      "   [185 224  35]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 55  54 196]\n",
      "   [113  80  58]\n",
      "   [ 62  55 141]\n",
      "   ...\n",
      "   [160  67  56]\n",
      "   [164 120  21]\n",
      "   [143  71 123]]\n",
      "\n",
      "  [[ 23 189 209]\n",
      "   [ 42 194 167]\n",
      "   [ 43 192 175]\n",
      "   ...\n",
      "   [191 102 153]\n",
      "   [193 161  58]\n",
      "   [190 207 145]]\n",
      "\n",
      "  [[223  24  42]\n",
      "   [197  40  40]\n",
      "   [180  23  52]\n",
      "   ...\n",
      "   [195 104 175]\n",
      "   [210 152 196]\n",
      "   [190  85 181]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[112 150  23]\n",
      "   [ 64 131  55]\n",
      "   [100  95  28]\n",
      "   ...\n",
      "   [206 169  56]\n",
      "   [152 206 185]\n",
      "   [161 162 216]]\n",
      "\n",
      "  [[108 239  17]\n",
      "   [ 55 207  90]\n",
      "   [ 33 128  54]\n",
      "   ...\n",
      "   [ 58 109 150]\n",
      "   [202 162 144]\n",
      "   [230 173 101]]\n",
      "\n",
      "  [[125 229  86]\n",
      "   [ 75  49  81]\n",
      "   [ 97  52  52]\n",
      "   ...\n",
      "   [ 88 127 142]\n",
      "   [186  67 106]\n",
      "   [169 202  64]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 75 216  81]\n",
      "   [ 65 169  52]\n",
      "   [142  63 101]\n",
      "   ...\n",
      "   [ 69  97  90]\n",
      "   [ 71  82 115]\n",
      "   [165  32 125]]\n",
      "\n",
      "  [[ 33 224 168]\n",
      "   [169  97  63]\n",
      "   [ 83  98 147]\n",
      "   ...\n",
      "   [113  76 102]\n",
      "   [ 98  66  39]\n",
      "   [174 190  82]]\n",
      "\n",
      "  [[ 33 112 247]\n",
      "   [ 90  76 223]\n",
      "   [ 76  82 129]\n",
      "   ...\n",
      "   [133 212  99]\n",
      "   [124 131 129]\n",
      "   [233 109  94]]]\n",
      "\n",
      "\n",
      " [[[ 92 159  27]\n",
      "   [ 49 128  61]\n",
      "   [ 95 101  36]\n",
      "   ...\n",
      "   [220 114  71]\n",
      "   [193 118 180]\n",
      "   [153 150 241]]\n",
      "\n",
      "  [[ 91 193  27]\n",
      "   [ 61 195  97]\n",
      "   [ 61 189  58]\n",
      "   ...\n",
      "   [ 81  37 134]\n",
      "   [ 64 161 100]\n",
      "   [195 188 110]]\n",
      "\n",
      "  [[118  10  17]\n",
      "   [ 67  50  84]\n",
      "   [ 66  62  37]\n",
      "   ...\n",
      "   [129  92 135]\n",
      "   [ 86 144  67]\n",
      "   [107 200  57]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 85 233 212]\n",
      "   [ 63 176  71]\n",
      "   [173  73 184]\n",
      "   ...\n",
      "   [ 30  73 179]\n",
      "   [182  68 150]\n",
      "   [154 162 112]]\n",
      "\n",
      "  [[ 32 218 229]\n",
      "   [197  85  97]\n",
      "   [195  97 199]\n",
      "   ...\n",
      "   [ 59 102  94]\n",
      "   [ 96  60  34]\n",
      "   [172 227  69]]\n",
      "\n",
      "  [[ 54 102 247]\n",
      "   [107  90 230]\n",
      "   [ 96  86 143]\n",
      "   ...\n",
      "   [ 84 215  80]\n",
      "   [ 63 136 102]\n",
      "   [185 106  66]]]\n",
      "\n",
      "\n",
      " [[[115 157   9]\n",
      "   [ 57 131  47]\n",
      "   [ 90  99 107]\n",
      "   ...\n",
      "   [202 172  60]\n",
      "   [160 195 187]\n",
      "   [159 164 224]]\n",
      "\n",
      "  [[109 235  12]\n",
      "   [ 39 198  92]\n",
      "   [ 23 126  62]\n",
      "   ...\n",
      "   [ 54 102 152]\n",
      "   [211 155 143]\n",
      "   [225 178  99]]\n",
      "\n",
      "  [[119 230  82]\n",
      "   [ 65 101  66]\n",
      "   [ 93  36  48]\n",
      "   ...\n",
      "   [ 64 124 151]\n",
      "   [193  66 111]\n",
      "   [160 203  63]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 55 223 249]\n",
      "   [ 42 175 224]\n",
      "   [ 55  55 159]\n",
      "   ...\n",
      "   [ 70  97  90]\n",
      "   [ 79  90 122]\n",
      "   [169  30 132]]\n",
      "\n",
      "  [[ 16 207  55]\n",
      "   [ 20 108  93]\n",
      "   [ 58  89 159]\n",
      "   ...\n",
      "   [111  80 101]\n",
      "   [ 97  71  43]\n",
      "   [174 191  83]]\n",
      "\n",
      "  [[ 51  91 219]\n",
      "   [ 82  94 197]\n",
      "   [105 100 138]\n",
      "   ...\n",
      "   [129 212 100]\n",
      "   [120 129 130]\n",
      "   [230 104  91]]]]\n"
     ]
    }
   ],
   "source": [
    "transformed_path = args[\"data_path\"]\n",
    "sinsegmentar_path = \"./data/input/COVIDGR1.0reducido-SinSegmentar\"\n",
    "\n",
    "test_files = os.listdir(args[\"data_path\"])\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
