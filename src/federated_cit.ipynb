{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/mnt/sdd/fcastro/envs/TF/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "import shfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\"data_path\":\"../data/COVIDGR1.0reducido/centralized/cropped-split\", \n",
    "        \"output_path\": \"../weights\",\n",
    "        \"input_path\": \"\",\n",
    "        \"model_name\":\"transferlearning.model\", \n",
    "        \"label_bin\": \"lb.pickle\", \n",
    "        \"batch_size\": 8,\n",
    "        \"federated_rounds\": 1,\n",
    "        \"epochs_per_FL_round\": 1,\n",
    "        \"num_nodes\": 2,\n",
    "        \"size_averaging\": 1,\n",
    "        \"random_rotation\": 0,\n",
    "        \"random_shift\": 0, \n",
    "        \"random_zoom\": 0,\n",
    "        \"horizontal_flip\": False,        \n",
    "        \"finetune\": True,\n",
    "        \"train_network\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training for labels: ['N', 'P']\n",
      "[INFO] Number of train images: 16\n",
      "[INFO] Number of test images: 4\n",
      "[INFO] Distributing the train set across the nodes...\n",
      "[INFO] done\n"
     ]
    }
   ],
   "source": [
    "LABELS = [\"N\", \"P\"]\n",
    "print(\"[INFO] training for labels: \" + str(LABELS))\n",
    "database = shfl.data_base.DatabaseFromDirectory(args[\"data_path\"], height = 256, width = 256)\n",
    "train_data, train_labels, test_data, test_labels = database.load_data()\n",
    "\n",
    "print(\"[INFO] Number of train images: \" + str(len(train_data)))\n",
    "print(\"[INFO] Number of test images: \" + str(len(test_data)))\n",
    "\n",
    "print(\"[INFO] Distributing the train set across the nodes...\")\n",
    "iid_distribution = shfl.data_distribution.IidDataDistribution(database)\n",
    "federated_data, test_data, test_label = iid_distribution.get_federated_data(num_nodes=args[\"num_nodes\"])\n",
    "print(\"[INFO] done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CITModel import CITModel\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda:7' if torch.cuda.is_available() else 'cpu')\n",
    "def model_builder():    \n",
    "    return CITModel(LABELS, classifier_name = \"resnet18\", lambda_value = 0.00075, batch_size=8, epochs=1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] FREEZING\n",
      "[INFO] FREEZING\n",
      "[INFO] FREEZING\n",
      "[INFO] FREEZING\n",
      "[INFO] FREEZING\n",
      "[INFO] FREEZING\n",
      "[INFO] FREEZING\n",
      "[INFO] FREEZING\n",
      "[INFO] FREEZING\n",
      "[INFO] FREEZING\n",
      "Accuracy round 0\n",
      "[INFO] weights = [1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0/1] Loss_D: 0.4488 Acc_D: 0.5000 Loss_G_class1: 10020.9307 Loss_G_class2: 6248.4468: 100%|██████████| 1/1 [00:01<00:00,  1.89s/it]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] weights = [1. 1.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0/1] Loss_D: 0.4074 Acc_D: 0.5000 Loss_G_class1: 9437.0664 Loss_G_class2: 5697.4790: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x7f9f35898390>: [0.6873142719268799, 0.5]\n",
      "Test performance client <shfl.private.federated_operation.FederatedDataNode object at 0x7f9f358982e8>: [0.6861069202423096, 0.5]\n",
      "Global model test performance : [0.6813296675682068, 0.5]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aggregator = shfl.federated_aggregator.FedAvgAggregator()\n",
    "federated_government = shfl.federated_government.FederatedGovernment(model_builder, federated_data, aggregator)\n",
    "federated_government.run_rounds(args[\"federated_rounds\"], test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "[[1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]]\n",
      "[[1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "[[0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "from shfl.private import UnprotectedAccess\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import copy\n",
    "\n",
    "\n",
    "def sample_loader(sample):\n",
    "    loader = transforms.Compose([transforms.ToTensor()])\n",
    "    s = loader(sample).float()\n",
    "    s = Variable(s, requires_grad=False)\n",
    "    s = s.unsqueeze(0)  #this is for VGG, may not be needed for ResNet\n",
    "    return s.to(device) #assumes that you're using GPU\n",
    "\n",
    "def show_img(G_dict, sample):\n",
    "    x = sample_loader(sample)\n",
    "    class_name = LABELS[0]\n",
    "    y = G_dict[class_name](x)\n",
    "    y = ToPILImage()(y[0].cpu().detach())\n",
    "    #y.save(\"./prueba.png\")\n",
    "    display(y)\n",
    "    \n",
    "def transform_data(G_dict, class_names, data, labels):\n",
    "    new_labels = []\n",
    "    new_data = []\n",
    "    for i in range(len(data)):\n",
    "        sample = data[i]\n",
    "        label = labels[i]\n",
    "        x = sample_loader(sample)\n",
    "        for class_name in class_names:\n",
    "            y = G_dict[class_name](x)\n",
    "            y = y[0].cpu().detach().numpy()\n",
    "            new_data.append(y)\n",
    "            new_label = str(label) + \"T\" + class_name\n",
    "            new_labels.append(new_label)\n",
    "    \n",
    "    lb = LabelBinarizer()\n",
    "    new_labels = lb.fit_transform(new_labels)\n",
    "    \n",
    "    return np.asarray(new_data), np.asarray(new_labels)\n",
    "\n",
    "\n",
    "G_dict = federated_government.global_model._G_dict\n",
    "for class_name in LABELS:\n",
    "    G_dict[class_name]= G_dict[class_name].to(device)\n",
    "federated_data.configure_data_access(UnprotectedAccess())\n",
    "\n",
    "new_federated_data = copy.deepcopy(federated_data)\n",
    "\n",
    "for i in range(federated_data.num_nodes()):\n",
    "    data_node = federated_data[i]\n",
    "    new_data_node = new_federated_data[i]\n",
    "    data = data_node.query()._data\n",
    "    labels = data_node.query()._label\n",
    "    new_data, new_labels = transform_data(G_dict, LABELS, data, labels)\n",
    "    new_data_node.query()._data = new_data\n",
    "    new_data_node.query()._label = new_labels\n",
    "    \n",
    "    print(data_node.query()._label)\n",
    "    print(new_data_node.query()._label)\n",
    "    #data_node.query()._data = new_data\n",
    "    #data_node.query()._label = new_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
